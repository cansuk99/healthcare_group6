{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36dcecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# The purpose of this script is to find statistical associations between features\n",
    "# and a binary target (readmission within 30 days) using GLMs (logistic regression)\n",
    "# =========================\n",
    "# Builds univariate & multivariable GLMs (logistic), fixes encoding/feature names,\n",
    "# handles mixed dtypes, sanitizes column names for Patsy,\n",
    "# and writes three Swiss-Excel-friendly outputs:\n",
    "#  - reports/clean_univariate_results.csv\n",
    "#  - reports/clean_multivariable_results.csv\n",
    "#  - reports/final_feature_summary_no_shap.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "DATA_PATH = \"../data/processed/diabetes_cleaned_data.csv\"\n",
    "TARGET = \"readmitted_binary\"  # must be 0/1\n",
    "TOP_FEATURES = None           # if None â†’ use all except IDs\n",
    "RARE_THRESH = 0.01            # collapse rare categories (<1%)\n",
    "SAMPLE_N = 100000              # stratified sample for speed; set None for all rows\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def read_csv_safely(path, expected_sep=None):\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=expected_sep or None, engine=\"python\",\n",
    "                           encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, sep=expected_sep or None, engine=\"python\",\n",
    "                           encoding=\"latin-1\", on_bad_lines=\"skip\")\n",
    "\n",
    "def strip_weird_chars(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = ''.join(ch for ch in text if ch.isprintable())\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    return text\n",
    "\n",
    "def clean_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [strip_weird_chars(str(c)).strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def save_swiss_excel(df, path):\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, sep=';', decimal=',', index=False)\n",
    "    return path\n",
    "\n",
    "# ---------- Load & prepare ----------\n",
    "df = read_csv_safely(DATA_PATH)\n",
    "df = clean_columns(df)\n",
    "TOP_FEATURES = None  # <- put your list here, e.g. [\"number_inpatient\",\"insulin\",\"age\",...]\n",
    "if TOP_FEATURES is None:\n",
    "    candidates = [\n",
    "        # demographics & admin\n",
    "        \"age\",\"gender\",\"race\",\"admission_type_id\",\"admission_source_id\",\"discharge_disposition_id\",\"payer_code\",\n",
    "        # utilization\n",
    "        \"number_inpatient\",\"number_outpatient\",\"number_emergency\",\n",
    "        # current stay & treatment\n",
    "        \"time_in_hospital\",\"num_lab_procedures\",\"num_procedures\",\"num_medications\",\n",
    "        \"insulin\",\"change\",\"diabetesMed\",\n",
    "        # diabetes specifics\n",
    "        \"A1Cresult\",\"max_glu_serum\",\"diab_type\",\"diab_control\",\n",
    "        \"diab_complication_binary\",\"diab_complication_categories\", \"diag_1\",\"diag_2\",\"diag_3\",\"num_diagnoses\", \n",
    "        \"diag_1_category\",\"diag_2_category\",\"diag_3_category\"\n",
    "    ]\n",
    "    TOP_FEATURES = [c for c in candidates if c in df.columns]\n",
    "\n",
    "use_cols = [TARGET] + TOP_FEATURES\n",
    "data = df[use_cols].dropna().copy()\n",
    "data[TARGET] = data[TARGET].astype(int)\n",
    "\n",
    "# ---------- Identify categorical columns ----------\n",
    "LIKELY_CATS = {\n",
    "    'race', 'gender', 'age',\n",
    "    'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "    'payer_code', 'medical_specialty',\n",
    "    'A1Cresult', 'max_glu_serum',\n",
    "    'change', 'diabetesMed', 'insulin',\n",
    "    'diag_1', 'diag_2', 'diag_3',\n",
    "    'diab_type', 'diab_control',\n",
    "    'diab_complication_binary', 'diab_complication_categories'\n",
    "}\n",
    "\n",
    "for c in TOP_FEATURES:\n",
    "    if c in LIKELY_CATS or data[c].dtype == object:\n",
    "        data[c] = data[c].astype(\"category\")\n",
    "\n",
    "cat_cols = [c for c in TOP_FEATURES if str(data[c].dtype).startswith(\"category\")]\n",
    "num_cols = [c for c in TOP_FEATURES if c not in cat_cols]\n",
    "\n",
    "# ---------- Collapse rare categorical levels safely ----------\n",
    "for c in cat_cols:\n",
    "    data[c] = data[c].astype(\"string\")\n",
    "    vc = data[c].value_counts(normalize=True, dropna=False)\n",
    "    rare = set(vc[vc < RARE_THRESH].index)\n",
    "    if rare:\n",
    "        data.loc[data[c].isin(rare), c] = \"Other\"\n",
    "    data[c] = data[c].astype(\"category\")\n",
    "\n",
    "# ---------- Optional sampling ----------\n",
    "if SAMPLE_N and len(data) > SAMPLE_N:\n",
    "    data = (data.groupby(TARGET, group_keys=False)\n",
    "                .apply(lambda x: x.sample(int(SAMPLE_N * len(x)/len(data)), random_state=42))\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "# ---------- Make column names Patsy-safe ----------\n",
    "def make_safe(name):\n",
    "    return re.sub(r'[^0-9a-zA-Z_]', '_', str(name))\n",
    "\n",
    "orig_to_safe = {c: make_safe(c) for c in data.columns}\n",
    "safe_to_orig = {v: k for k, v in orig_to_safe.items()}\n",
    "data = data.rename(columns=orig_to_safe)\n",
    "\n",
    "TARGET_SAFE = orig_to_safe[TARGET]\n",
    "TOP_FEATURES_SAFE = [orig_to_safe[c] for c in TOP_FEATURES]\n",
    "cat_cols_safe = [orig_to_safe[c] for c in cat_cols]\n",
    "num_cols_safe = [orig_to_safe[c] for c in num_cols]\n",
    "\n",
    "# ---------- Categorical casting for Patsy ----------\n",
    "for col in cat_cols_safe:\n",
    "    data[col] = data[col].astype(str)\n",
    "\n",
    "# ---------- Build formulas ----------\n",
    "def term(col): \n",
    "    return f\"C({col})\" if col in cat_cols_safe else col\n",
    "\n",
    "uni_formulas = {c: f\"{TARGET_SAFE} ~ {term(c)}\" for c in TOP_FEATURES_SAFE}\n",
    "mv_formula   = f\"{TARGET_SAFE} ~ \" + \" + \".join(term(c) for c in TOP_FEATURES_SAFE)\n",
    "\n",
    "# ---------- Fit multivariable GLM ----------\n",
    "glm_mv = smf.glm(formula=mv_formula, data=data, family=sm.families.Binomial()).fit()\n",
    "\n",
    "mv = glm_mv.summary2().tables[1].copy()\n",
    "mv = mv.rename(columns={\"Coef.\":\"coef\",\"Std.Err.\":\"stderr\",\"P>|z|\":\"p_value\",\n",
    "                        \"[0.025\":\"ci_low\",\"0.975]\":\"ci_high\"})\n",
    "mv[\"term\"] = mv.index.astype(str)\n",
    "def base_from_term(term: str) -> str:\n",
    "    if not isinstance(term, str):\n",
    "        return str(term)\n",
    "    m = re.match(r\"C\\((.*?)\\)\", term)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return re.split(r'[\\[:]', term)[0]\n",
    "mv[\"feature_safe\"] = mv[\"term\"].apply(base_from_term)\n",
    "mv[\"feature\"] = mv[\"feature_safe\"].map(safe_to_orig).fillna(mv[\"feature_safe\"])\n",
    "mv[\"OR\"] = np.exp(mv[\"coef\"])\n",
    "mv[\"OR_ci_low\"] = np.exp(mv[\"ci_low\"])\n",
    "mv[\"OR_ci_high\"] = np.exp(mv[\"ci_high\"])\n",
    "mv = mv[[\"feature\",\"term\",\"coef\",\"OR\",\"OR_ci_low\",\"OR_ci_high\",\"stderr\",\"z\",\"p_value\"]]\n",
    "mv_path = save_swiss_excel(mv, \"../reports/clean_multivariable_results.csv\")\n",
    "\n",
    "# ---------- Fit univariate GLMs ----------\n",
    "uni_rows = []\n",
    "for safe_feat, formula in uni_formulas.items():\n",
    "    try:\n",
    "        m = smf.glm(formula=formula, data=data, family=sm.families.Binomial()).fit()\n",
    "        t = m.summary2().tables[1].copy()\n",
    "        t = t.rename(columns={\"Coef.\":\"coef\",\"Std.Err.\":\"stderr\",\"P>|z|\":\"p_value\",\n",
    "                              \"[0.025\":\"ci_low\",\"0.975]\":\"ci_high\"})\n",
    "        t[\"term\"] = t.index.astype(str)\n",
    "        t[\"feature_safe\"] = safe_feat\n",
    "        t[\"feature\"] = safe_to_orig.get(safe_feat, safe_feat)\n",
    "        t[\"OR\"] = np.exp(t[\"coef\"])\n",
    "        t[\"OR_ci_low\"] = np.exp(t[\"ci_low\"])\n",
    "        t[\"OR_ci_high\"] = np.exp(t[\"ci_high\"])\n",
    "        uni_rows.append(t[[\"feature\",\"term\",\"coef\",\"OR\",\"OR_ci_low\",\"OR_ci_high\",\"stderr\",\"z\",\"p_value\"]])\n",
    "    except Exception:\n",
    "        uni_rows.append(pd.DataFrame([{\n",
    "            \"feature\": safe_to_orig.get(safe_feat, safe_feat), \"term\": \"ERROR\",\n",
    "            \"coef\": np.nan, \"OR\": np.nan, \"OR_ci_low\": np.nan, \"OR_ci_high\": np.nan,\n",
    "            \"stderr\": np.nan, \"z\": np.nan, \"p_value\": np.nan\n",
    "        }]))\n",
    "uni = pd.concat(uni_rows, ignore_index=True)\n",
    "uni_path = save_swiss_excel(uni, \"../reports/clean_univariate_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
