{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d783578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ar/Desktop/hslu/2 Semester/Data Science in Healthcare/healthcare_group6/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 1.000\n",
      "PR-AUC (AP): 1.000\n",
      "F1 (thr=0.5): 0.999\n",
      "\n",
      "Top selected terms (absolute coef):\n",
      "                                   feature      coef\n",
      "         num_lab_procedures readmitted_<30  0.181156\n",
      "            num_medications readmitted_<30  0.133655\n",
      "          num_lab_procedures readmitted_NO -0.096971\n",
      "         num_lab_procedures readmitted_>30 -0.086587\n",
      "           number_diagnoses readmitted_<30  0.077382\n",
      "             num_medications readmitted_NO -0.074555\n",
      "            num_medications readmitted_>30 -0.063180\n",
      "            number_diagnoses readmitted_NO -0.045285\n",
      "           time_in_hospital readmitted_<30  0.037512\n",
      "           number_diagnoses readmitted_>30 -0.037368\n",
      "            time_in_hospital readmitted_NO -0.020669\n",
      "           time_in_hospital readmitted_>30 -0.018496\n",
      "             num_procedures readmitted_<30  0.011745\n",
      "glimepiride-pioglitazone_No readmitted_<30  0.010596\n",
      "             citoglipton_No readmitted_<30  0.010596\n",
      "           acetohexamide_No readmitted_<30  0.010596\n",
      "  metformin-pioglitazone_No readmitted_<30  0.010596\n",
      "            troglitazone_No readmitted_<30  0.010596\n",
      " metformin-rosiglitazone_No readmitted_<30  0.010596\n",
      "                 examide_No readmitted_<30  0.010596\n",
      "\n",
      "Saved:\n",
      " - reports/selected_interactions_l1.csv\n",
      " - reports/model_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# The purpose of this script is to efficiently generate\n",
    "# and select all pairwise feature interactions using L1-regularized logistic regression.\n",
    "# ============================================\n",
    "# - Generates all 2-way interactions (after one-hot)\n",
    "# - Uses L1 (Lasso) logistic regression to select features\n",
    "# - Much faster and memory-friendly than dense GLM(**2)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, f1_score\n",
    ")\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_PATH = \"data/processed/diabetes_cleaned_data.csv\"\n",
    "TARGET = \"readmitted_binary\"\n",
    "DROP_COLS = [\"encounter_id\", \"patient_nbr\"]  # exclude IDs\n",
    "TEST_SIZE = 0.25\n",
    "SEED = 42\n",
    "\n",
    "# L1 regularization strength: smaller C => stronger regularization\n",
    "C_REG = 0.5\n",
    "MAX_ITER = 600\n",
    "\n",
    "# Optional: downsample while iterating if you need speed\n",
    "SAMPLE_N = None  # e.g., 20000; set None to use all rows\n",
    "\n",
    "# ---------------- Load ----------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns], errors=\"ignore\")\n",
    "df = df.dropna(subset=[TARGET]).copy()\n",
    "df[TARGET] = df[TARGET].astype(int)\n",
    "\n",
    "# Optional sampling for speed while prototyping\n",
    "if SAMPLE_N is not None and len(df) > SAMPLE_N:\n",
    "    # stratified sampling to keep outcome prevalence\n",
    "    pos = df[df[TARGET]==1].sample(frac=min(1.0, SAMPLE_N/len(df)), random_state=SEED)\n",
    "    neg_needed = SAMPLE_N - len(pos)\n",
    "    neg = df[df[TARGET]==0].sample(n=max(0, neg_needed), random_state=SEED)\n",
    "    df = pd.concat([pos, neg]).sample(frac=1, random_state=SEED)\n",
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].values\n",
    "\n",
    "# Identify categoricals heuristically (object dtype or known categorical names)\n",
    "likely_cats = {\n",
    "    'race','gender','age','admission_type_id','discharge_disposition_id','admission_source_id',\n",
    "    'payer_code','medical_specialty','A1Cresult','max_glu_serum','change','diabetesMed','insulin',\n",
    "    'diag_1','diag_2','diag_3','diab_type','diab_control','diab_complication_binary','diab_complication_categories'\n",
    "}\n",
    "cat_cols = [c for c in X.columns if (X[c].dtype == 'object') or (c in likely_cats)]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# ---------------- Split ----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "# ---------------- Pipeline ----------------\n",
    "# 1) One-hot encode categoricals (sparse)\n",
    "# 2) Generate all 2-way interactions (no self-squared terms), keep sparse\n",
    "# 3) L1-logistic (saga) to select useful interactions & main effects\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0  # keep sparse matrices\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", pre),\n",
    "    (\"poly\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    (\"logit\", LogisticRegression(\n",
    "        penalty=\"l1\", solver=\"saga\", C=C_REG, max_iter=MAX_ITER, n_jobs=-1, random_state=SEED\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------------- Fit ----------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ---------------- Evaluate ----------------\n",
    "probs = pipe.predict_proba(X_test)[:, 1]\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "roc = roc_auc_score(y_test, probs)\n",
    "ap = average_precision_score(y_test, probs)\n",
    "prec, rec, _ = precision_recall_curve(y_test, probs)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(f\"ROC-AUC: {roc:.3f}\")\n",
    "print(f\"PR-AUC (AP): {ap:.3f}\")\n",
    "print(f\"F1 (thr=0.5): {f1:.3f}\")\n",
    "\n",
    "# ---------------- Inspect selected interactions/features ----------------\n",
    "# Get names after one-hot\n",
    "ohe = pipe.named_steps[\"prep\"].named_transformers_.get(\"cat\")\n",
    "num_names = num_cols\n",
    "cat_names = list(ohe.get_feature_names_out(cat_cols)) if ohe is not None else []\n",
    "base_feature_names = np.array(num_names + cat_names)\n",
    "\n",
    "# Names after PolynomialFeatures (interaction_only=True)\n",
    "poly = pipe.named_steps[\"poly\"]\n",
    "# sklearn >= 1.0: get_feature_names_out is available\n",
    "try:\n",
    "    poly_names = poly.get_feature_names_out(base_feature_names)\n",
    "except:\n",
    "    # fallback for very old versions\n",
    "    poly_names = poly.get_feature_names(base_feature_names)\n",
    "\n",
    "coef = pipe.named_steps[\"logit\"].coef_.ravel()\n",
    "nz_idx = np.flatnonzero(coef)  # selected by L1\n",
    "selected = pd.DataFrame({\n",
    "    \"feature\": np.array(poly_names)[nz_idx],\n",
    "    \"coef\": coef[nz_idx]\n",
    "}).sort_values(\"coef\", key=np.abs, ascending=False)\n",
    "\n",
    "# Save reports\n",
    "Path(\"reports\").mkdir(parents=True, exist_ok=True)\n",
    "selected.to_csv(\"reports/selected_interactions_l1.csv\", index=False)\n",
    "pd.DataFrame({\n",
    "    \"metric\":[\"ROC_AUC\",\"PR_AUC\",\"F1_thr_0.5\"],\n",
    "    \"value\":[roc, ap, f1]\n",
    "}).to_csv(\"reports/model_metrics.csv\", index=False)\n",
    "\n",
    "print(f\"\\nTop selected terms (absolute coef):\")\n",
    "print(selected.head(20).to_string(index=False))\n",
    "print(\"\\nSaved:\")\n",
    "print(\" - reports/selected_interactions_l1.csv\")\n",
    "print(\" - reports/model_metrics.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
